<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on HabitsLab</title>
    <link>http://localhost:1313/HabitsLab-projectPage/</link>
    <description>Recent content in Homepage on HabitsLab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Dec 2021 15:09:31 -0600</lastBuildDate><atom:link href="http://localhost:1313/HabitsLab-projectPage/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>TITLE</title>
      <link>http://localhost:1313/HabitsLab-projectPage/news/news3/</link>
      <pubDate>Wed, 05 Jan 2022 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/news/news3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Balancing Privary with Visual Confirmation Utility in Activity-Oriented Wearable Cameras</title>
      <link>http://localhost:1313/HabitsLab-projectPage/projects/project3/</link>
      <pubDate>Tue, 04 Jan 2022 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/projects/project3/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>Dr. Alshurafa receives NSF EAGER Award</title>
      <link>http://localhost:1313/HabitsLab-projectPage/news/news2/</link>
      <pubDate>Mon, 03 Jan 2022 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/news/news2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Put Publication Name Here</title>
      <link>http://localhost:1313/HabitsLab-projectPage/publications/template_page/</link>
      <pubDate>Fri, 03 Dec 2021 21:27:40 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/publications/template_page/</guid>
      <description>1. Introduction Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph
RQ1: Question Question Question Question Question Question Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph Paragraph</description>
    </item>
    
    <item>
      <title>Balancing Privary with Visual Confirmation Utility in Activity-Oriented Wearable Cameras</title>
      <link>http://localhost:1313/HabitsLab-projectPage/publications/publication1/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/publications/publication1/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>GRANT NAME</title>
      <link>http://localhost:1313/HabitsLab-projectPage/grants/grant3/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/grants/grant3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GRANT NAME</title>
      <link>http://localhost:1313/HabitsLab-projectPage/grants/grant4/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/grants/grant4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paper Accepted at ACM IMWUT (Ubicomp) 2019</title>
      <link>http://localhost:1313/HabitsLab-projectPage/news/news1/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/news/news1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privary with Visual Confirmation Utility in Activity-Oriented Wearable Cameras</title>
      <link>http://localhost:1313/HabitsLab-projectPage/projects/project1/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/projects/project1/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>Publication Publication Publication Publication Publication Publication Publication Publication</title>
      <link>http://localhost:1313/HabitsLab-projectPage/publications/publication2/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/publications/publication2/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>with Visual Confirmation Utility in Activity-Oriented Wearable Cameras</title>
      <link>http://localhost:1313/HabitsLab-projectPage/projects/project2/</link>
      <pubDate>Fri, 03 Dec 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/projects/project2/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>EAT: A Reliable Eating Assessment Technology for Free-living Individuals.</title>
      <link>http://localhost:1313/HabitsLab-projectPage/grants/grant2/</link>
      <pubDate>Thu, 04 Nov 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/grants/grant2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SenseWhy: Overeating in Obesity Through the Lens of Passive Sensing</title>
      <link>http://localhost:1313/HabitsLab-projectPage/grants/grant1/</link>
      <pubDate>Tue, 05 Oct 2021 15:09:31 -0600</pubDate>
      
      <guid>http://localhost:1313/HabitsLab-projectPage/grants/grant1/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
