<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grants on HabitsLab</title>
    <link>https://HAbitsLab.github.io/grants/</link>
    <description>Recent content in Grants on HabitsLab</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jul 2021 15:09:31 -0600</lastBuildDate><atom:link href="https://HAbitsLab.github.io/grants/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>EAT: A Reliable Eating Assessment Technology for Free-living Individuals</title>
      <link>https://HAbitsLab.github.io/grants/eat/</link>
      <pubDate>Tue, 27 Jul 2021 15:09:31 -0600</pubDate>
      
      <guid>https://HAbitsLab.github.io/grants/eat/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>WildCam: A Privacy Conscious Wearable Eating Detection Camera People will Actually Wear in the Wild</title>
      <link>https://HAbitsLab.github.io/grants/wildcam/</link>
      <pubDate>Fri, 29 Jan 2021 15:09:31 -0600</pubDate>
      
      <guid>https://HAbitsLab.github.io/grants/wildcam/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>BehaviorSight: Privacy Enhancing Wearable System to Detect Health Risk Behaviors in Real-time</title>
      <link>https://HAbitsLab.github.io/grants/behaviorsight/</link>
      <pubDate>Mon, 07 Sep 2020 15:09:31 -0600</pubDate>
      
      <guid>https://HAbitsLab.github.io/grants/behaviorsight/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>Early-Stage Interdisciplinary Collaboration: Privacy Enhancing Framework to Advance Behavior Models</title>
      <link>https://HAbitsLab.github.io/grants/early-stage-interdisciplinary-collaboration/</link>
      <pubDate>Wed, 05 Jun 2019 15:09:31 -0600</pubDate>
      
      <guid>https://HAbitsLab.github.io/grants/early-stage-interdisciplinary-collaboration/</guid>
      <description>Demo demo demo demo
demo demo demo</description>
    </item>
    
    <item>
      <title>SenseWhy: Overeating in Obesity Through the Lens of Passive Sensing</title>
      <link>https://HAbitsLab.github.io/grants/sensewhy/</link>
      <pubDate>Tue, 05 Dec 2017 15:09:31 -0600</pubDate>
      
      <guid>https://HAbitsLab.github.io/grants/sensewhy/</guid>
      <description>1. Introduction Wearable cameras are used as a tool to understand fine-grained human activities in the wild because of their ability to provide visual information that can be interpreted by humans [15, 45, 55] or machines [6, 43, 48]. Particularly in the ubiquitous computing (UbiComp) community, wearable cameras are increasingly being used to obtain visually confirmed annotations of wearers’ activities in real-world settings, which is necessary to both understand human.</description>
    </item>
    
    <item>
      <title>EAGER: Privacy Enhancing Framework to Advance Behavior Models</title>
      <link>https://HAbitsLab.github.io/grants/nsf-eager-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://HAbitsLab.github.io/grants/nsf-eager-/</guid>
      <description>1. Introduction This project is designed to advance research on problematic eating behavior. The project investigates wearable sensors to measure eating behavior and developing models of behavior that comprise multiple observable behaviors such as eating alone or with friends, or chewing speed. These data can help scientists improve upon current traditional methods such as self-reported eating diaries, which tend to be inconsistent, sparse, and rarely timely. We capture human behavior using a custom wearable augmented camera.</description>
    </item>
    
  </channel>
</rss>
